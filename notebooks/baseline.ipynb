{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 12:03:28.401660: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-24 12:03:28.597854: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-24 12:03:28.600034: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 12:03:30.128552: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "# Notification\n",
    "import time\n",
    "\n",
    "# File IO\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "# Deep learning\n",
    "# Keras-related imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
    "from keras.layers import Convolution1D, MaxPooling2D, Convolution2D\n",
    "from keras import backend as K\n",
    "# K.set_image_dim_ordering('th')\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import RemoteMonitor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "# Result processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0: Perform feature transform, save data\n",
    "\n",
    "This section is used to create the $(\\mathbf{X},y)$ training set with feature choice parameterised by either `{'log-mel', 'mfcc'}`. Librosa is used to extract the features, and has further support for any features one may wish to choose.\n",
    "\n",
    "Once this section has been run once, the user is advised to skip to **Section 1** which deals with performing a baseline classification using a Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameterise feature transform here. The default is to use log-mel features, but the user may implement any choice\n",
    "# or use the raw time-series as preferred \n",
    "\n",
    "feature_type = 'log-mel'  # Select from {'log-mel', 'mfcc'}\n",
    "\n",
    "\n",
    "win_len = 0.1  # Window length of feature\n",
    "n_mels = 128  # Number of log-mel coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the root of the processed 1 second audio chunks, where votes have been aggregated already\n",
    "# This path is relative, and should by default point to the correct location\n",
    "\n",
    "wav_root = '../data/audio_1sec/'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the label information contained in the resolved 1 second chunks, with votes {'yes', 'no', 'not_sure'}\n",
    "\n",
    "df = pd.read_csv('../labels/audio_1sec.csv',  header=None, names=[\"path\", \"yes\", \"no\", \"not_sure\",\"subject_set\"])\n",
    "df['path'] = df['path'].astype(str) + '.wav'\n",
    "\n",
    "\n",
    "# Create the y vector by treating 'not_sure' as 0.5, 'yes' as 1.0, 'no' as 0.0 and average\n",
    "df['res'] = (df['yes'].astype(int)*1 + df['not_sure'].astype(int)*0.5) / (df['yes'] + df['no'] + df['not_sure']) >= 0.5\n",
    "total_audio_n = len(df.index.values.tolist())\n",
    "\n",
    "y = np.zeros((total_audio_n, 2))\n",
    "\n",
    "y[:,1] = np.array(np.array(df['res']).astype(int)).astype(int)\n",
    "y[:,0] = 1-y[:,1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialise dimensions for feature transformation\n",
    "\n",
    "nfft = int(win_len * 8000)\n",
    "wav_path = wav_root + df[\"path\"]\n",
    "\n",
    "# Initialise empty X matrix\n",
    "wav, fs = librosa.load(wav_path.iloc[0],sr=None)  # Load one spectrogram file to calculate dimensions of entire set\n",
    "\n",
    "if feature_type == 'log-mel':    \n",
    "    spec = librosa.feature.melspectrogram(y=wav, sr=fs, n_mels=n_mels, n_fft=nfft*4, hop_length=nfft)\n",
    "             \n",
    "elif feature_type == 'mfcc':\n",
    "    spec = librosa.feature.mfcc(y=wav, sr=fs, n_mfcc=13, n_fft=nfft*4, hop_length=nfft)\n",
    "    \n",
    "l_spec = np.shape(spec)[1]  # Length of the spectral representation for each 2 second chunk\n",
    "h_spec = np.shape(spec)[0]  # This is also n_mels\n",
    "spec_matrix = np.zeros([len(y), h_spec, l_spec])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 0 2054\n",
      "Iteration 1000 14 1181\n",
      "Iteration 2000 28 1118\n",
      "Iteration 3000 40 1061\n",
      "Iteration 4000 53 1059\n",
      "Iteration 5000 64 1030\n",
      "Iteration 6000 76 1021\n",
      "Iteration 7000 89 1017\n",
      "Iteration 8000 102 1025\n",
      "Iteration 9000 115 1024\n",
      "Iteration 10000 127 1019\n",
      "Iteration 11000 141 1022\n",
      "Iteration 12000 152 1014\n",
      "Iteration 13000 165 1011\n",
      "Iteration 14000 176 1006\n",
      "Iteration 15000 189 1006\n",
      "Iteration 16000 200 998\n",
      "Iteration 17000 211 990\n",
      "Iteration 18000 221 982\n",
      "Iteration 19000 234 981\n",
      "Iteration 20000 246 980\n",
      "Iteration 21000 258 979\n",
      "Iteration 22000 270 979\n",
      "Iteration 23000 283 980\n",
      "Iteration 24000 295 980\n",
      "Iteration 25000 309 986\n",
      "Iteration 26000 321 983\n",
      "Iteration 27000 333 984\n",
      "Iteration 28000 342 974\n",
      "Iteration 29000 349 960\n",
      "Iteration 30000 359 953\n",
      "Iteration 31000 375 964\n",
      "Iteration 32000 388 967\n",
      "Iteration 33000 401 969\n",
      "Iteration 34000 412 966\n",
      "Iteration 35000 423 963\n",
      "Iteration 36000 431 955\n",
      "Iteration 37000 440 948\n",
      "Iteration 38000 450 943\n",
      "Iteration 39000 459 938\n",
      "Iteration 40000 469 934\n",
      "Iteration 41000 478 930\n",
      "Iteration 42000 488 926\n",
      "Iteration 43000 497 922\n",
      "Iteration 44000 507 919\n",
      "Iteration 45000 517 915\n",
      "Iteration 46000 527 912\n",
      "Iteration 47000 537 910\n",
      "Iteration 48000 547 908\n",
      "Iteration 49000 557 906\n",
      "Iteration 50000 568 904\n",
      "Iteration 51000 578 902\n",
      "Iteration 52000 588 901\n",
      "Iteration 53000 599 900\n",
      "Iteration 54000 608 898\n",
      "Iteration 55000 619 897\n",
      "Iteration 56000 629 895\n",
      "Iteration 57000 640 894\n",
      "Iteration 58000 650 893\n",
      "Iteration 59000 661 893\n",
      "Iteration 60000 671 892\n",
      "Iteration 61000 681 890\n",
      "Iteration 62000 693 890\n",
      "Iteration 63000 703 889\n",
      "Iteration 64000 714 889\n",
      "Iteration 65000 725 888\n",
      "Iteration 66000 736 888\n",
      "Iteration 67000 747 888\n",
      "Iteration 68000 756 886\n",
      "Iteration 69000 763 881\n",
      "Iteration 70000 770 876\n",
      "Iteration 71000 777 872\n",
      "Iteration 72000 784 867\n",
      "Iteration 73000 790 863\n",
      "Iteration 74000 797 858\n",
      "Iteration 75000 805 855\n",
      "Iteration 76000 812 851\n",
      "Iteration 77000 820 848\n",
      "Iteration 78000 827 844\n",
      "Iteration 79000 834 841\n"
     ]
    }
   ],
   "source": [
    "# Perform feature transformation and store result in pre-allocated spec_matrix\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(0, total_audio_n):\n",
    "#     if count[i] == 1:\n",
    "        \n",
    "        # Create X matrix\n",
    "    audio_file, fs = librosa.load(wav_path.loc[i],sr=None)\n",
    "    if feature_type == 'log-mel':\n",
    "        spec_matrix[i] = librosa.feature.melspectrogram(y=audio_file,\n",
    "                                                        sr=fs, n_mels=n_mels, n_fft=nfft*4, hop_length=nfft)\n",
    "\n",
    "    elif feature_type == 'mfcc':\n",
    "        spec_matrix[i] = librosa.feature.mfcc(y=audio_file,\n",
    "                                                        sr=fs, n_mfcc=13, n_fft=nfft*4, hop_length=nfft)            \n",
    "        \n",
    "    if i%1000 == 0:\n",
    "        time_used = time.time()-start_time\n",
    "        time_total = time_used * total_audio_n / (i+1)\n",
    "        \n",
    "        print('Iteration', str(i), \"%i\"%(time_used), \"%i\"%(time_total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save files with file_name if not in path\n",
    "\n",
    "file_names = ['data_log-melnot_sure_single_into_0_5.h5', 'label_log-melnot_sure_single_into_0_5.h5']\n",
    "\n",
    "for file_name in file_names:\n",
    "    if not os.path.isfile('../proc_data/' + file_name):\n",
    "        hf = h5py.File('../proc_data/data_' + feature_type + 'not_sure_single_into_0_5.h5', 'w')\n",
    "        hf.create_dataset('../proc_data/data_' + feature_type + '_majority_labels_not_sure_single_into_0_5',\n",
    "                          data=spec_matrix)\n",
    "        hf.close()\n",
    "        \n",
    "        hf = h5py.File('../proc_data/label_' + feature_type + 'not_sure_single_into_0_5.h5', 'w')\n",
    "        hf.create_dataset('../proc_data/label_' + feature_type + '_majority_labels_not_sure_single_into_0_5', data=y)\n",
    "        hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Load and classify\n",
    "\n",
    "If the feature transform has already been performed and the data is saved in `proc_data`, load the data in the cell below and perform classification as outlined by the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "feature_type = 'log-mel'\n",
    "save_name = 'not_sure_single_into_0_5'\n",
    "\n",
    "hf = h5py.File('../proc_data/data_' + feature_type + save_name + '.h5', 'r')\n",
    "spec_matrix_read = np.array(hf.get('../proc_data/data_' + feature_type + '_majority_labels_' + save_name))\n",
    "hf.close()\n",
    "\n",
    "hf = h5py.File('../proc_data/label_' + feature_type + save_name + '.h5', 'r')\n",
    "y = np.array(hf.get('../proc_data/label_' + feature_type + '_majority_labels_' + save_name))\n",
    "hf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dB\n",
    "\n",
    "spec_matrix_db = np.zeros_like(spec_matrix_read)\n",
    "\n",
    "for i, spec in enumerate(spec_matrix_read):\n",
    "    spec_matrix_db[i] = librosa.power_to_db(spec,ref=np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Convolutional Neural Network\n",
    "\n",
    "First, the data is split tenfold using `sklearn`'s `train_test_split` with the random states given in the `random_state` vector.\n",
    "\n",
    "The neural network cross-entropy weights are set in the dictionary `class_weight`, with the key `0` referring to the noise class, and `1` referring to the mosquito class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 12:27:23.974217: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 300596736 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/pluto/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/pluto/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/pluto/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/pluto/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/pluto/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/pluto/.local/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 128, 32, 1), found shape=(None, 1, 128, 11)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 48\u001b[0m\n\u001b[1;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     45\u001b[0m           optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     46\u001b[0m           metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 48\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m         \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m         \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x\u001b[38;5;241m=\u001b[39mX_test_tf, y\u001b[38;5;241m=\u001b[39my_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     55\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_tf)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/pluto/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     <a href='file:///home/pluto/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/pluto/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/pluto/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=69'>70</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/pluto/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=70'>71</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/pluto/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=71'>72</a>\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filea1bnssuo.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     <a href='file:///tmp/__autograph_generated_filea1bnssuo.py?line=12'>13</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///tmp/__autograph_generated_filea1bnssuo.py?line=13'>14</a>\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> <a href='file:///tmp/__autograph_generated_filea1bnssuo.py?line=14'>15</a>\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     <a href='file:///tmp/__autograph_generated_filea1bnssuo.py?line=15'>16</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     <a href='file:///tmp/__autograph_generated_filea1bnssuo.py?line=16'>17</a>\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/pluto/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/pluto/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/pluto/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/pluto/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/pluto/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/pluto/.local/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 128, 32, 1), found shape=(None, 1, 128, 11)\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for random_state in [10,20,30,40,50,60,70,80,90,100]:\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(spec_matrix_db, np.array(y), test_size=0.33,\n",
    "                                                            random_state=random_state)\n",
    "     # Normalise by statistics of training data\n",
    "     print(1)\n",
    "     X_train_norm = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "     X_test_norm = (X_test - np.mean(X_train))/np.std(X_train)\n",
    "     X_train_tf = X_train_norm.reshape(X_train_norm.shape[0], 1, X_train_norm.shape[1], X_train_norm.shape[2])\n",
    "     X_test_tf = X_test_norm.reshape(X_test_norm.shape[0], 1, X_test_norm.shape[1], X_test_norm.shape[2])\n",
    "\n",
    "     ################################ CONVOLUTIONAL NEURAL NETWORK ################################\n",
    "     ## NN parameters\n",
    "     class_weight = {0: 1.,\n",
    "                         1: 10.,\n",
    "                         }\n",
    "     input_shape = (1, X_train_tf.shape[2], X_train_tf.shape[-1])\n",
    "     print(1)\n",
    "     model = Sequential()\n",
    "     print(2)\n",
    "     n_dense = 128\n",
    "     nb_classes = 2\n",
    "     # number of convolutional filters\n",
    "     nb_conv_filters = 32\n",
    "     nb_conv_filters_2 = 64\n",
    "     input_shape = (128, 32, 1)\n",
    "\n",
    "     model = Sequential()\n",
    "     model.add(Conv2D(nb_conv_filters, kernel_size=(3, 3),\n",
    "                    activation='relu', padding='same', strides=1,\n",
    "                    input_shape=input_shape))\n",
    "     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "     model.add(Conv2D(nb_conv_filters_2, kernel_size=(3, 3),\n",
    "                    activation='relu', padding='same'))\n",
    "     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "     model.add(Flatten())\n",
    "     model.add(Dense(128, activation='relu'))\n",
    "     model.add(Dropout(0.5))\n",
    "     model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "     model.compile(loss='binary_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "     model.fit(x=X_train_tf, y=y_train, batch_size=None, epochs=3, verbose=1, callbacks=None, validation_split=0.0,\n",
    "              validation_data=None,\n",
    "              shuffle=True, class_weight=class_weight, sample_weight=None, initial_epoch=0,\n",
    "              steps_per_epoch=None, validation_steps=None)\n",
    "\n",
    "\n",
    "     loss, acc = model.evaluate(x=X_test_tf, y=y_test, batch_size=None, verbose=0, sample_weight=None, steps=None)\n",
    "     pred = model.predict(X_test_tf)\n",
    "     plt.hist(pred[:,1]) # Optional: visualise histogram of labels\n",
    "     #     plt.show()\n",
    "     print(random_state, loss, acc)\n",
    "     \n",
    "     pred_list.append(pred)  # Collect y_test to report classification performance\n",
    "     y_test_list.append(y_test)  # Collect y_test to report classification performance\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plotting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a function to display the confusion matrices. This is a slight modification of the `plot_confusion_matrix` function available on [sklearn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) to include a mean and variance, for the purpose of evaluation over a tenfold split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, std,\n",
    "                          normalize=False,\n",
    "                                                    cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    std = std * 100\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] *100\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.1f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt) + ' Â± ' + format(std[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "cm_list = []\n",
    "for i in np.arange(len(pred_list)):\n",
    "        cm_list.append(confusion_matrix(np.argmax(y_test_list[i],-1), np.argmax(pred_list[i],-1)))\n",
    "cm_mean = np.mean(cm_list, axis = 0)\n",
    "total = np.sum(cm_mean)\n",
    "cm_mean = cm_mean/total\n",
    "cm_std = np.std(cm_list, axis = 0)/total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format and display plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[85.36 14.64]\n",
      " [29.04 70.96]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "class_names= np.array(['Noise', 'Mozz'])\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(cm_mean, std=cm_std, classes=class_names, normalize=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
